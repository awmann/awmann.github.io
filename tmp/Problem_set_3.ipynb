{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>ASTR 519/719: Problem Set 3</center><center>CCDs and Telescopes</center><center>Due: Feb 22 via Sakai Drop Box</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing useful stuff!\n",
    "\n",
    "## Astropy will make this a lot easier!\n",
    "from astropy.io import fits\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "## you probably won't need these, but they can help make things look nicer\n",
    "#from IPython.display import Latex\n",
    "#from matplotlib.colors import LogNorm\n",
    "#from matplotlib import colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Included with the homework is a set of data taken with the LCO telescope network. This includes both target observations, and calibration data (darks, flats, and biases). These are taken at 3 different wavelengths, rp, V, and B. You can just consider these filters as red, green, and blue for now. The files are separated into folders based on data type. \n",
    "\n",
    "The homework is to build a basic data reduction pipeline for imaging data. This is split into smaller tasks below for simplicity, but I advise reading all problems first so you see where things are heading when designing your code. With your notebook/code, please upload your final stacked image for each filter. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "Read in one of the images, and find the following quantities from the header or image data:\n",
    "\n",
    "a) The CCD gain and readnoise\n",
    "\n",
    "b) The exposure time in seconds\n",
    "\n",
    "c) The 'overscan' region\n",
    "The LCO headers (annoyingly) often say 'UNKNOWN' in 'BAISSEC'. \n",
    "Instead, check TRIMSEC (region lacking the overscan) and DATASEC (all pixels including overscan) to determine the overscan region. It should near the edge of the detector.\n",
    "\n",
    "d) The filter\n",
    "\n",
    "e) The observation type (e.g., flat, bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Make a histogram of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g) Display/plot the image (with matplotlib.pyplot.imshow). Adjust the scaling (e.g., log scaling) and range (ignore outliers) to make the image more clear (use the information from your histogram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "\n",
    "Write a function(s) to loop over all files (including calibrations) perform the folling procedures:\n",
    "\n",
    "-Take the median value in the overscan region and subtract it from the image. \n",
    "\n",
    "-Trim the overscan region (cut it from the image, making the array smaller).\n",
    "\n",
    "-Save the updated images (overscan subtracted and trimmed) in separate folders or with a new names (to avoid overwriting raw data). You might need to update the axis parameters in the headers.\n",
    "\n",
    "You may assume all data has the same overscan region (but not the same value), rather than identify it dynamically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "\n",
    "Write a function to median stack a list of files. For this, find the median value of each pixel across all images to be stacked. For input, the function should take a text file containing a list of names, a folder containing all data, or an array of filenames to be stacked. The function should return the stacked 2D image, which can be saved to a new file. \n",
    "\n",
    "Run this function on the (overscan-subtracted) biases to create a master bias frame and save it. \n",
    "\n",
    "Hint: Stack overflow has multiple posts making suggestions for how to do a median stack. You are welcome to copy these, but you must confirm that they work as expected if you are trusting an outside source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "Write a function (or set of functions) to perform all remaining reduction to the imaging data. The function can assume you have folders as provided (separating out flats/biases/images). It should use the median stacking code from above, and perform the following tasks:\n",
    "\n",
    "-Subtract the bias level from all data (using the master frame from Problem 3).\n",
    "\n",
    "-Median stack the bias- & overscan-subtracted darks.\n",
    "\n",
    "-Remove the dark current from all flats/images using the master frame (after scaling according to the exposure times)\n",
    "\n",
    "-Normalize the corrected flat fields to 1.\n",
    "\n",
    "-Median stack the bias- and dark-subtracted normalized flats.\n",
    "\n",
    "-Divide (bias/dark/overscan subtracted) object data by the normalized master flat.\n",
    "\n",
    "-Median stack the 10 reduced images for each filter.\n",
    "\n",
    "Run the pipeline on the provided data. Save the three reduced/stacked images (one for each filter). Inspect the files in Fits Liberator or DS9 to check for obvious problems with the stacked images. Upload the reduced files with your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5 (extra credit)\n",
    "\n",
    "Make a single-call version of the pipeline above. The program should take as input only the path to a list of files. It should automatically decide what is a bias/flat/image based on the header, subtract the overscan (you can manually code the overscan region since it is the same for all images) and output reduced and stacked images for each filter. Reminder that the filter matters for flats, but not biases/darks. \n",
    "\n",
    "Test the code by copying/moving all the data from various folders into one folder and running it. \n",
    "\n",
    "You are encouraged to use your definitions/code from above. The task is to make this a single-call pipeline, not to reproduce the reduction steps from scratch.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
